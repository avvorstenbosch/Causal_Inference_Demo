---
title: 'Causal Inference Demo'
author: "Alex van Vorstenbosch"
date: "`r format(Sys.time(), '%d %B, %Y')`"
fontsize: 10pt
output:
  beamer_presentation: 
    theme: "hannover"
    colortheme: "dolphin"
header-includes:
  - \usepackage{tikz}
  - \usepackage{multicol}
  - \usepackage{hyperref}
---

```{r setup II, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(eval = TRUE, cache=TRUE, echo = FALSE, warning = FALSE, message = FALSE, dev = 'pdf')
```

```{r packages}
library(tidyverse)
library(dagitty)
library(brms) # bayesian analyse
library(broom) # voor tidy regressie resultaten
library(broom.mixed) # broom voor brms
library(tidybayes) # voor extracting samples
library(ggridges) # voor ggridges plots
set.seed(300)
```


# What are we going to see

* Defining the problem
* DAG
* Simulating the data
* Can we use BRMS to retreive the parameters
* \textbf{Real World Data...}
* Is our dag valid?
* Results



# Defining the Problem

* Mathematics is on of THE fundamental school subject...
* ...yet, it is stereotypically seen as boring and difficult.
* In this demo we explore what influences school performance in Math
* ... and possible intervention paths we could use.
* As outcome variable we take the end of year grade in Mathematics for high school students.

# DAG - The Full Causal Pentagram
```{r fig1, out.width="80%", fig.align = "center"}
dag <- dagitty('dag {
bb="-4.361,-3.907,6.053,5.052"
EducationParents [pos="0.165,-2.506"]
ExtraEducationSupport [pos="-2.624,0.509"]
Grade [outcome,pos="0.128,0.557"]
HigherEducationAspiration [pos="-1.235,-0.496"]
InternetAcces [pos="-0.979,-1.746"]
PaidCourses [pos="-0.488,2.606"]
RegionHouse [pos="-2.460,-2.562"]
Sex [pos="2.442,-1.390"]
SocietalBias [latent,pos="1.391,-0.504"]
StudyTime [pos="-2.019,2.583"]
EducationParents -> Grade
EducationParents -> HigherEducationAspiration
ExtraEducationSupport -> Grade
ExtraEducationSupport -> PaidCourses
HigherEducationAspiration -> ExtraEducationSupport
HigherEducationAspiration -> Grade
HigherEducationAspiration -> PaidCourses
HigherEducationAspiration -> StudyTime
InternetAcces -> Grade
PaidCourses -> Grade
RegionHouse -> EducationParents
RegionHouse -> HigherEducationAspiration
RegionHouse -> InternetAcces
Sex -> SocietalBias
SocietalBias -> Grade
SocietalBias -> HigherEducationAspiration
StudyTime -> ExtraEducationSupport
StudyTime -> Grade
StudyTime -> PaidCourses
}
')
plot(dag)
```
The unmeasured variable SocietalBias explains how the student's Sex effects Grade and HigherEducationAspiration.
However, since Sex is only a 'Mechanism', we can remove it from the DAG and simplify it. 


<!--
This causal model is one of the mental models one might design for features influencing final grades.
We are not saying this model is correct. In fact, this model might communicate a rather simplistic view.

One might add many more features, but this will over complicate the model, even this DAG is already rather complex.
The most important part is that we communicate this DAG, as it informs other on the assumptions behind our models.

Important to note is that a subject such as making a DAG, and as a consequence simulating data from this Data Generating Process (DGP),
might feel like a sensitive subject. Quite rightfully so. Just remember, it feels sensitive because you are being very explicit about assumptions, which makes you vulnerable.
In any other analysis you might have done, you bake in the same set of assumptions, but you don't make them as explicit, giving a false sense of protection and safety!
-->

# DAG - The (slightly simplified) Causal Pentagram
```{r fig2, out.width="80%", fig.align = "center"}
dag <- dagitty('dag {
bb="-4.361,-3.907,6.053,5.052"
EducationParents [pos="0.165,-2.506"]
ExtraEducationSupport [pos="-2.624,0.509"]
Grade [outcome,pos="0.128,0.557"]
HigherEducationAspiration [pos="-1.235,-0.496"]
InternetAcces [pos="-0.979,-1.746"]
PaidCourses [pos="-0.488,2.606"]
RegionHouse [pos="-2.460,-2.562"]
Sex [pos="2.442,-1.390"]
StudyTime [pos="-2.019,2.583"]
EducationParents -> Grade
EducationParents -> HigherEducationAspiration
ExtraEducationSupport -> Grade
ExtraEducationSupport -> PaidCourses
HigherEducationAspiration -> ExtraEducationSupport
HigherEducationAspiration -> Grade
HigherEducationAspiration -> PaidCourses
HigherEducationAspiration -> StudyTime
InternetAcces -> Grade
PaidCourses -> Grade
RegionHouse -> EducationParents
RegionHouse -> HigherEducationAspiration
RegionHouse -> InternetAcces
Sex -> Grade
Sex -> HigherEducationAspiration
StudyTime -> ExtraEducationSupport
StudyTime -> Grade
StudyTime -> PaidCourses
}
')
plot(dag)
```
This DAG is slightly simpler, but the 'Causal Pentagram' looks like it might cause problems.
Time to find out!

# Simulate data
```{r}
#Starting in the upper half of the DAG
N=500
RegionHouse = sample(x = c("R", "U"), size=N, replace=TRUE, prob=c(0.3,0.7))

EducationParents = ifelse(RegionHouse=="U",
                          sample(x = 0:1, size=N, replace=TRUE, prob=c(0.4,0.6)),
                          sample(x = 0:1, size=N, replace=TRUE, prob=c(0.6,0.4)))

InternetAcces = ifelse(RegionHouse=="U",
                          sample(x = c(TRUE,FALSE), size=N, replace=TRUE, prob=c(0.85,0.15)),
                          sample(x = c(TRUE,FALSE), size=N, replace=TRUE, prob=c(0.95,0.05)))

Sex = sample(x = c("M", "F"), size=N, replace=TRUE, prob=c(0.5,0.5))

CalcHigherEducation <- function(RegionHouse, EducationParents, Sex){
  # Samples HigherEducationAspiration based on 3 inputs.
  # Assumption: Growing up in a rural region you may be less motivated to go to college.
  # Assumption: Due to societal pressure, women might be less likely to persue college. 
  HEA_base = 0.6
  Sex_effect = ifelse(Sex=="M", 0.05, -0.05)
  EducationParents_effect = ifelse(Sex==1,-0.1,0.1)
  RegionHouse_effect = ifelse(RegionHouse=="R", -0.05, 0.05)
  HEA_p = HEA_base + Sex_effect + EducationParents_effect + RegionHouse_effect
  HEA = rbernoulli(n=length(HEA_p) ,p=HEA_p)
  return(HEA)
}
HigherEducationAspiration = CalcHigherEducation(RegionHouse, EducationParents, Sex)

StudyTime = ifelse(HigherEducationAspiration==1,
                   sample(x = 0:3, size=N, replace=TRUE, prob=c(0.15,0.15,0.35,0.35)),
                   sample(x = 0:3, size=N, replace=TRUE, prob=c(0.3,0.35,0.25,0.1))
)

CalcExtraEducationSupport <- function(HigherEducationAspiration, StudyTime){
  # Samples ExtraEducationSupport based on 2 inputs
  # Assumption: If you are good at doing homework yourself (more hours), you get less support
  # Assumption: If you are motivated to go to college, you might seek out more support even if you study a lot
  EAS_base = 0.2
  HEA_effect = ifelse(HigherEducationAspiration==1, 0.075, -0.05)
  StudyTime_effect = -0.025*StudyTime
  EAS_p = EAS_base + HEA_effect + StudyTime_effect
  EAS = rbernoulli(n=length(EAS_p) ,p=EAS_p)
  return(EAS)
}
ExtraEducationalSupport = CalcExtraEducationSupport(HigherEducationAspiration, StudyTime)
  
CalcPaidCourses <- function(StudyTime, HigherEducationAspiration, ExtraEducationalSupport){
  # Samples PaidCourses based on 3 inputs
  # Assumption: If you study little, and get no extra support, but want to go to college,
  #             you might try to catch up using paid courses
  # Assumption: The opposite might also be true, college + many hours studying + extra support,
  #             may mean the student is more likely to also pay for extra courses
  Paid_base = 0.05
  effect = rep(0, length(StudyTime))
  for (i in length(StudyTime)){
    if(StudyTime[i]<2 & HigherEducationAspiration[i]==1 & ExtraEducationalSupport[i]==0){
      effect[i] = 0.1
    } else if(StudyTime[i]>3 & HigherEducationAspiration[i]==1 & ExtraEducationalSupport[i]==1){
      effect[i] = 0.1
    }
  }
  Paid_p = Paid_base + effect
  Paid = rbernoulli(n=length(Paid_p) ,p=Paid_p)
}
PaidCourses = CalcPaidCourses(StudyTime, HigherEducationAspiration, ExtraEducationalSupport)
  
```

## Simulated grades distribution
```{r}
# Finally, calculate grade
set.seed(925)
Grade = rnorm(n=500, mean=5.0, sd=0.3) + 
  1*PaidCourses +
  0.5*StudyTime + 
  1*ExtraEducationalSupport +
  0.7*HigherEducationAspiration +
  0.6*InternetAcces -0.6 + #convenient way to get include negative effect
  ifelse(EducationParents==1, 0.5, -1) +
  ifelse(Sex=="F", -0.25, 0.25)
```
```{r fig3, out.width="80%", fig.align = "center"}
plot_data = data.frame(Grade)
ggplot(plot_data) + 
  geom_histogram(aes(x=Grade), closed="left", fill="royalblue1", color='white', breaks=seq(1.0,10,0.5), show.legend=TRUE) + 
  labs(title=paste("Distribution of 500 Simulated Math Grades"), subtitle="By Alex", x="Grade", y="Counts (#)") +
  scale_x_continuous(breaks=seq(1,10,1))
```
In our simulation, Most students score between a 5.5 and a 6. This seems reasonable.
Also, very high scores are rare, as well as extremely low scores. The distribution is roughly normal, but not quite. 

# Retrieve these direct effects using BRMS

```{r}
fullrun <- 1

# We add 0 + intercept in order to stop BRMS from centering the model, now we can properly fit Intercept as in the original simulation
Formula <- Grade ~ 0  + Intercept + 
                        PaidCourses +
                        StudyTime +
                        ExtraEducationalSupport +
                        HigherEducationAspiration +
                        InternetAcces + 
                        EducationParents +
                        Sex 
    
sim_data <- data.frame(PaidCourses,
                        StudyTime,
                        ExtraEducationalSupport,
                        HigherEducationAspiration,
                        InternetAcces,
                        EducationParents,
                        Sex, 
                        Grade)

priors <- c(set_prior("normal(5.5, 0.5)", class = "b", coef = "Intercept"),
            set_prior("normal(0, 0.5)", class = "b", coef = "PaidCoursesTRUE"),
            set_prior("normal(0, 0.5)", class = "b", coef = "StudyTime"),
            set_prior("normal(0, 0.5)", class = "b", coef = "ExtraEducationalSupportTRUE"),
            set_prior("normal(0, 0.5)", class = "b", coef = "HigherEducationAspirationTRUE"),
            set_prior("normal(0, 0.5)", class = "b", coef = "InternetAccesTRUE"),
            set_prior("normal(0, 0.5)", class = "b", coef = "EducationParents"),
            set_prior("normal(0, 0.5)", class = "b", coef = "SexM"))

if(fullrun){
  model_math <- brm(
              formula = Formula,
              prior = priors,
              data   = sim_data,
              warmup = 500, 
              iter   = 10000, 
              chains = 6, 
              inits  = "random",
              cores  = 6,
              seed = 123,
              backend = "cmdstanr",
              control = list(adapt_delta = 0.99, 
                             max_treedepth = 17),
              silent = TRUE,
              refresh = 0)
  
  saveRDS(model_math, "./models/model_demo.rds")
} else {
  model_math <- readRDS("./models/model_demo.rds")
}
```

# Checking our posterior and chains!

```{r fig4, out.width="80%", fig.align = "center"}
model_math %>%
  plot(combo = c("hist", "trace"), widths = c(1, 1.5),
       theme = theme_bw(base_size = 10),
       ask   = FALSE
       )
  
```
Good mixing, and clean normal estimates for all parameters!
```{r}
summary(model_math)
```

```{r}
# now we sample from the model in order to show our predictions
samples_math <- tidy_draws(model_math) %>%
  dplyr::select(starts_with("b_")) %>%
  pivot_longer(cols = 1:8, names_to = "Model1", values_to = "Value") %>%
  mutate(Feature = as.factor(str_sub(Model1, 3))) %>%
  dplyr::select(Feature, Value)

real_vals <- data.frame(params = c("StudyTime", "SexM", "PaidCoursesTRUE", "InternetAccesTRUE", "Intercept", "HigherEducationAspirationTRUE", "ExtraEducationalSupportTRUE", "EducationParents"),
                       True_Value = c(0.5, 0.5, 1, 0.6, 3.15, 0.7, 1, 1.5))
                       
samples_math <- left_join(samples_math, real_vals, by = c("Feature" = "params")) 
                       
```

# Bayesian Parameter Estimates 

```{r fig5, out.width="80%", fig.align = "center"}
ggplot(samples_math, aes(x=Value, y=Feature, fill=Feature)) +
  geom_density_ridges2(scale = 0.9, 
                       quantile_lines=TRUE,
                       quantile_fun=function(x,...)mean(x)) +
  scale_fill_viridis_d() +
  geom_segment(data=samples_math,aes(x = True_Value,
                   xend = True_Value,
                   y = as.numeric(as.factor(Feature)),
                   yend = as.numeric(as.factor(Feature))+1),
               color = "red", fill="red") +
  theme(legend.position = "none") +
  labs(y = " ", x = "coefficient estimates", title="Bayesian parameter estimates") + 
  scale_x_continuous(breaks=seq(0,3.25,0.25))
```
Almost all Parameter values are perfectly retrieved! PaidCourses is slightly underestimated,
And Sex is slighty overestimated. But these results are very promising

# How does the model perform in terms of predictions?
```{r}
preds_raw <- as_tibble(predict(model_math, newdata = sim_data))

preds <- cbind(sim_data, preds_raw)

plot_data = preds %>%
            mutate(pred_min=Estimate-Est.Error,
                   pred_max=Estimate+Est.Error)
```

```{r fig6, out.width="80%", fig.align = "center"}
ggplot() +
    geom_errorbar(data = plot_data, aes(x = Grade, xend = Grade, ymin=pred_min, ymax = pred_max), size=0.1, width=0.1, color = "red") +
  geom_point(data = plot_data, aes(x = Grade, y = Estimate)) +
  geom_abline(intercept = 0, slope = 1, color = "firebrick", linetype = "dashed") +
  labs(y = "Predicted Grade", x = "True Grade", title="Grade vs. Predicted Grade")+
  scale_x_continuous(breaks=seq(1,10,1)) +
  scale_y_continuous(breaks=seq(1,10,1)) +
  coord_fixed()


```
* This looks good! Most estimates overlap the true value within 1 sigma deviation.
* Estimates seem consistent across the whole domain



